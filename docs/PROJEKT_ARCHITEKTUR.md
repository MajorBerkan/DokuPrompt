# CaffeineCode - Projekt-Architektur und Funktionsweise

## ğŸ“‹ Inhaltsverzeichnis

1. [Projekt-Ãœbersicht](#projekt-Ã¼bersicht)
2. [Architektur-Ãœberblick](#architektur-Ã¼berblick)
3. [Komponenten im Detail](#komponenten-im-detail)
4. [Wie wird die Datenbank gespeichert?](#wie-wird-die-datenbank-gespeichert)
5. [Wie wird alles gestartet?](#wie-wird-alles-gestartet)
6. [Datenfluss und Interaktionen](#datenfluss-und-interaktionen)

---

## Projekt-Ãœbersicht

**CaffeineCode** ist eine Code-Dokumentations-Plattform, die Repositories automatisch klonen, analysieren und mit KI-gestÃ¼tzten Dokumentationen versehen kann.

### Technologie-Stack

- **Backend**: FastAPI (Python 3.12)
- **Datenbank**: PostgreSQL 16 mit pgvector-Extension (fÃ¼r Vektorsuche)
- **Cache/Queue**: Redis 7
- **Task Queue**: Celery (fÃ¼r asynchrone Background-Jobs)
- **Frontend**: React + Vite
- **Container**: Docker & Docker Compose
- **KI-Integration**: LangChain + Anthropic Claude

---

## Architektur-Ãœberblick

Das System folgt einer **Microservices-Architektur** mit folgenden Hauptkomponenten:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Docker Network                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Frontend â”‚â”€â”€â”€â”€â–¶â”‚ Backend  â”‚â”€â”€â”€â”€â–¶â”‚PostgreSQLâ”‚            â”‚
â”‚  â”‚  (React) â”‚     â”‚ (FastAPI)â”‚     â”‚   +      â”‚            â”‚
â”‚  â”‚  :5173   â”‚     â”‚  :8000   â”‚     â”‚ pgvector â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â”‚  :5432   â”‚            â”‚
â”‚                        â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                        â”‚                                     â”‚
â”‚                        â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Redis   â”‚            â”‚
â”‚                        â”‚            â”‚  :6379   â”‚            â”‚
â”‚                        â”‚            â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜            â”‚
â”‚                        â”‚                  â”‚                 â”‚
â”‚                   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”            â”‚                 â”‚
â”‚                   â”‚  Celery  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                   â”‚  Worker  â”‚                              â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚ Adminer  â”‚  (DB-Management UI)                          â”‚
â”‚  â”‚  :8081   â”‚                                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Komponenten im Detail

### 1. **PostgreSQL Datenbank** (Port 5432)

**Image**: `pgvector/pgvector:pg16`

#### Funktionen:
- Speichert alle Anwendungsdaten persistent
- Nutzt **pgvector** Extension fÃ¼r Vektor-Embeddings (KI-gestÃ¼tzte Suche)
- Nutzt **citext** fÃ¼r case-insensitive Text
- Nutzt **pgcrypto** fÃ¼r VerschlÃ¼sselung

#### Datenbank-Schema:

**Haupttabellen**:
- `users` - Benutzer mit Entra-ID-Integration
- `repositories` - Geklonte Git-Repositories
- `repo_clones` - Clone-Job-Status und -Historie
- `prompts` - KI-Prompt-Templates
- `prompt_runs` - AusgefÃ¼hrte Prompt-Jobs
- `documents` - Generierte Dokumentationen
- `document_files` - Dokumentationsdateien
- `user_repo_roles` - Zugriffsberechtigungen

#### Konfiguration:
```env
POSTGRES_DB=codedoc
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
```

---

### 2. **Backend (FastAPI)** (Port 8000)

**Technologie**: Python 3.12, FastAPI, SQLAlchemy, Uvicorn

#### Hauptaufgaben:
- REST-API fÃ¼r Frontend
- Datenbank-Operationen (CRUD)
- Git-Repository-Management
- KI-Integration (LangChain + Anthropic)
- Job-Scheduling (Celery-Tasks anstoÃŸen)

#### API-Routen:
- `/` - Root & Healthcheck
- `/health` - Systemstatus
- `/health/db` - Datenbankverbindung prÃ¼fen
- `/api/repos/*` - Repository-Management
- `/api/ai/*` - KI-gestÃ¼tzte Funktionen
- `/api/prompts/*` - Prompt-Verwaltung
- `/api/docs/*` - Dokumentations-API

#### Wichtige Module:
- `app/main.py` - FastAPI-Anwendung & Startup
- `app/database.py` - Datenbank-Connection
- `app/db/models.py` - SQLAlchemy-Modelle
- `app/db/init_db.py` - DB-Initialisierung
- `app/services/` - Business-Logik
- `app/api/` - API-Routen

---

### 3. **Redis** (Port 6379)

**Image**: `redis:7-alpine`

#### Funktionen:
- **Message Broker** fÃ¼r Celery (Task-Queue)
- **Result Backend** fÃ¼r Celery (Job-Ergebnisse)
- Cache fÃ¼r Session-Daten (optional)

---

### 4. **Celery Worker**

**Technologie**: Celery + Redis

#### Aufgaben:
- **Asynchrone Background-Jobs**:
  - Git-Repository klonen
  - Repository analysieren
  - KI-Dokumentation generieren
  - GroÃŸe Datenverarbeitungen

#### Warum Celery?
- Lange laufende Tasks blockieren nicht das Backend
- Retry-Mechanismus bei Fehlern
- Status-Tracking von Jobs
- Skalierbar (mehrere Worker mÃ¶glich)

#### Konfiguration:
```python
celery_app = Celery(
    "codedoc_worker",
    broker="redis://redis-server:6379/0",
    backend="redis://redis-server:6379/0"
)
```

---

### 5. **Frontend (React + Vite)** (Port 5173)

**Technologie**: React, Vite, TailwindCSS

#### Funktionen:
- Single-Page-Application (SPA)
- BenutzeroberflÃ¤che fÃ¼r:
  - Repository-Verwaltung
  - Dokumentations-Ansicht
  - Prompt-Editor
  - Job-Monitoring

#### Hot-Reload:
- Vite Dev-Server mit `--host` flag fÃ¼r Docker
- `CHOKIDAR_USEPOLLING=true` fÃ¼r File-Watching in Docker

---

### 6. **Adminer** (Port 8081)

**Image**: `adminer:latest`

#### Funktionen:
- Web-basiertes Datenbank-Management-Tool
- Direkter Zugriff auf PostgreSQL
- NÃ¼tzlich fÃ¼r:
  - Schema-Inspektion
  - Daten-Debugging
  - SQL-Queries ausfÃ¼hren

---

## Wie wird die Datenbank gespeichert?

### Persistenz-Mechanismus

Die Datenbank wird durch **Docker Volumes** persistent gespeichert:

```yaml
volumes:
  postgres_data:  # Named Volume
```

#### Was bedeutet das?

1. **Named Volume `postgres_data`**:
   - Docker erstellt ein Volume auf dem Host-System
   - Speicherort (Linux): `/var/lib/docker/volumes/postgres_data/_data`
   - Speicherort (Windows/Mac): In der Docker Desktop VM

2. **Gemountet in Container**:
   ```yaml
   volumes:
     - postgres_data:/var/lib/postgresql/data
   ```
   - PostgreSQL schreibt alle Daten in `/var/lib/postgresql/data`
   - Dieses Verzeichnis ist mit dem Host-Volume verbunden

3. **Persistenz garantiert**:
   - Daten bleiben erhalten, auch wenn Container gestoppt/gelÃ¶scht werden
   - Nur durch `docker-compose down -v` oder `docker volume rm` lÃ¶schbar

### Datenbank-Initialisierung

Beim ersten Start:

```python
# app/db/init_db.py
def init_db():
    # 1. PostgreSQL-Extensions aktivieren
    init_extensions()  # pgvector, citext, pgcrypto
    
    # 2. Schema erstellen (Tabellen, Indizes)
    Base.metadata.create_all(bind=engine)
```

**SQLAlchemy** erstellt automatisch alle Tabellen basierend auf den Models in `app/db/models.py`.

---

## Wie wird alles gestartet?

### Start-Prozess mit Docker Compose

#### Befehl:
```bash
docker-compose up -d
```

#### Ablauf:

1. **Docker Compose liest `docker-compose.yml`**
   - Erstellt Docker-Netzwerk fÃ¼r alle Services
   - Erstellt Volumes (`postgres_data`, `frontend_node_modules`)

2. **Services werden in AbhÃ¤ngigkeitsreihenfolge gestartet**:

   **Phase 1: Basis-Services**
   ```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ PostgreSQL  â”‚     â”‚   Redis     â”‚
   â”‚  (startup)  â”‚     â”‚  (startup)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚
          â–¼ (healthcheck)     â–¼
       [HEALTHY]          [STARTED]
   ```

   - **PostgreSQL**: Startet und fÃ¼hrt Healthcheck aus
     ```yaml
     healthcheck:
       test: ["CMD-SHELL", "pg_isready -U postgres"]
       interval: 5s
     ```
   - **Redis**: Startet (kein Healthcheck nÃ¶tig)

   **Phase 2: Backend-Services** (warten auf PostgreSQL + Redis)
   ```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   Backend   â”‚     â”‚   Celery    â”‚
   â”‚  :8000      â”‚     â”‚   Worker    â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   â”‚
          â–¼                   â–¼
    init_db()            Wartet auf Jobs
   ```

   - **Backend**:
     - `depends_on` wartet auf PostgreSQL (healthy) und Redis (started)
     - FÃ¼hrt `init_db()` aus (Extensions + Schema)
     - Startet Uvicorn: `uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload`
   
   - **Celery Worker**:
     - `depends_on` wartet auf PostgreSQL (healthy) und Redis (started)
     - Startet Worker: `celery -A app.worker.celery_app.celery_app worker`

   **Phase 3: Frontend & Tools** (warten auf Backend)
   ```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Frontend   â”‚     â”‚   Adminer   â”‚
   â”‚  :5173      â”‚     â”‚   :8081     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ```

   - **Frontend**:
     - `depends_on` wartet auf Backend
     - FÃ¼hrt `npm install` aus
     - Startet Vite: `npm run dev -- --host`
   
   - **Adminer**:
     - `depends_on` wartet auf PostgreSQL
     - Web-UI unter `http://localhost:8081`

3. **Netzwerk-Verbindungen werden hergestellt**:
   - Alle Container kÃ¶nnen sich Ã¼ber Service-Namen ansprechen
   - z.B. Backend â†’ `postgres://postgres:5432`
   - z.B. Backend â†’ `redis://redis-server:6379`

4. **Ports werden auf Host gemappt**:
   - Frontend: `localhost:5173`
   - Backend: `localhost:8000`
   - PostgreSQL: `localhost:5432`
   - Redis: `localhost:6379`
   - Adminer: `localhost:8081`

### Start-Logs anzeigen:

```bash
# Alle Logs live anzeigen
docker-compose logs -f

# Nur Backend-Logs
docker-compose logs -f backend

# Nur Celery-Logs
docker-compose logs -f celery
```

### Services einzeln neu starten:

```bash
# Backend neu starten
docker-compose restart backend

# Celery neu starten
docker-compose restart celery

# Alle Services neu starten
docker-compose restart
```

### Komplett stoppen:

```bash
# Services stoppen (Daten bleiben erhalten)
docker-compose down

# Services stoppen + Volumes lÃ¶schen (Daten werden gelÃ¶scht!)
docker-compose down -v
```

---

## Datenfluss und Interaktionen

### Beispiel: Repository klonen

1. **Benutzer klickt "Repository hinzufÃ¼gen"** im Frontend
   ```
   Frontend â†’ POST /api/repos
   ```

2. **Backend erstellt Repository-Eintrag**
   ```python
   # In PostgreSQL:
   INSERT INTO repositories (name, remote_url, status)
   VALUES ('my-repo', 'https://github.com/...', 'pending')
   ```

3. **Backend startet Celery-Task**
   ```python
   from app.worker.tasks_git import clone_repository
   
   task = clone_repository.delay(repo_id=repo.id)
   # Task wird in Redis-Queue geschrieben
   ```

4. **Celery Worker holt Task aus Redis**
   ```python
   # Worker fÃ¼hrt aus:
   def clone_repository(repo_id):
       repo = db.query(Repository).get(repo_id)
       repo.status = "cloning"
       
       # Git-Clone durchfÃ¼hren
       git.Repo.clone_from(repo.remote_url, repo.target_dir)
       
       repo.status = "cloned"
       db.commit()
   ```

5. **Frontend zeigt Status**
   ```
   Frontend â†’ GET /api/repos/{id}
   Backend â†’ {"status": "cloned", ...}
   ```

### Beispiel: KI-Dokumentation generieren

1. **Benutzer wÃ¤hlt Repository und Prompt**
2. **Backend startet Celery-Task**
   ```python
   from app.worker.tasks_ai import generate_documentation
   
   task = generate_documentation.delay(
       repo_id=repo.id,
       prompt_id=prompt.id
   )
   ```

3. **Celery Worker**:
   - LÃ¤dt Repository-Code
   - LÃ¤dt Prompt-Template
   - Ruft LangChain + Claude API auf
   - Speichert generierte Dokumentation in PostgreSQL + Dateisystem

4. **Frontend zeigt Dokumentation**

---

## Umgebungsvariablen

Alle Konfigurationen sind in `.env`:

```env
# Datenbank
POSTGRES_DB=codedoc
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
DATABASE_URL=postgresql+psycopg://postgres:postgres@postgres:5432/codedoc

# Celery / Redis
CELERY_BROKER_URL=redis://redis-server:6379/0
CELERY_RESULT_BACKEND=redis://redis-server:6379/0

# Frontend
VITE_API_BASE_URL=http://127.0.0.1:8000

# KI
MODEL_NAME=eu.anthropic.claude-sonnet-4-20250514-v1:0
ANTHROPIC_API_KEY=sk-...
```

---

## NÃ¤chste Schritte

Siehe [DEPLOYMENT_GUIDE.md](./DEPLOYMENT_GUIDE.md) fÃ¼r:
- Produktions-Deployment auf Server
- Externe ZugriffsmÃ¶glichkeiten
- Tailscale-Integration
- SSL/TLS-Konfiguration
- Backup-Strategien
